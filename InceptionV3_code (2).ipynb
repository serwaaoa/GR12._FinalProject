{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68831cfa-e6e5-4bc3-8c5d-42656b58a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tensorflow.keras.models import clone_model\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0812d8f8-f262-444c-bdb6-c9c346331543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting path to downloaded dataset\n",
    "base_dir = r\"C:\\Users\\Dell Inspiron\\Documents\\School_2024_2\\Intro to AI\\Nigeria\\Data_Nigeria\"\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "whole_data = base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14fcb1-30ea-4305-9b35-aae27bcad383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To download directly\n",
    "#Installing kaggle\n",
    "!pip install kaggle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8cf850-8413-4002-8c9a-a7ca19b41fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placing Kaggle API at the right directory\n",
    "kaggle_dir = Path.home() / '.kaggle'\n",
    "kaggle_dir.mkdir(exist_ok=True)\n",
    "\n",
    "kaggle_json_path = kaggle_dir / 'kaggle.json'\n",
    "\n",
    "with open('kaggle.json') as f:\n",
    "    kaggle_creds = json.load(f)\n",
    "\n",
    "with open(kaggle_json_path, 'w') as f:\n",
    "    json.dump(kaggle_creds, f)\n",
    "\n",
    "kaggle_json_path.chmod(0o600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117fc72-c8d1-479e-999e-1c91fec3d8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading dataset\n",
    "!kaggle datasets download -d peaceedogun/nigerian-foods-and-snacks-multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b7aa62-66ca-4072-9cd7-8e1b3af59d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cross-checking for any corrupted images in dataset\n",
    "def check_corrupt_images(directory):\n",
    "    corrupt_images = []\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            filepath = os.path.join(subdir, file)\n",
    "            try:\n",
    "                img = Image.open(filepath)\n",
    "                img.verify()  # Verify that it is, in fact, an image\n",
    "            except (IOError, SyntaxError) as e:\n",
    "                print(f'Bad file: {filepath}')\n",
    "                corrupt_images.append(filepath)\n",
    "    return corrupt_images\n",
    "#Checking dataset\n",
    "corrupt_images = check_corrupt_images(r\"C:\\Users\\Dell Inspiron\\Documents\\School_2024_2\\Intro to AI\\Nigeria\\Data_Nigeria\")\n",
    "print(f'Found {len(corrupt_images)} corrupt images.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e923630-22a0-42e7-bd8f-53065526484c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_fp, test_fp, val_fp):\n",
    "    datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "    )\n",
    "    val_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "    )\n",
    "\n",
    "    train_gen = datagen.flow_from_directory(\n",
    "        train_fp,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    validation_gen = val_datagen.flow_from_directory(\n",
    "        val_fp,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    test_gen = val_datagen.flow_from_directory(\n",
    "        test_fp,\n",
    "        target_size=(299, 299),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    return train_gen, validation_gen, test_gen\n",
    "\n",
    "train_gen, validation_gen, test_gen = load_data(train_dir, test_dir, val_dir)\n",
    "print(f\"Number of training samples: {train_gen.samples}\")\n",
    "print(f\"Number of validation samples: {validation_gen.samples}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25218e88-e1cd-48f1-a86a-e470ab016187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing training data distribution to gain insights\n",
    "def plot_class_distribution(generator):\n",
    "    # Counting the number of samples for each class\n",
    "    class_counts = np.bincount(generator.classes)\n",
    "\n",
    "    # Getting the class names from the generator\n",
    "    class_names = list(generator.class_indices.keys())\n",
    "\n",
    "    # Creating a bar plot with class names on the x-axis and class counts on the y-axis\n",
    "    sns.barplot(x=class_names, y=class_counts)\n",
    "\n",
    "    # Rotating the x-axis labels for better readability if they are long\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Class Distribution for Training Data\")\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a254526-6c50-4f4e-97ec-e338f3fa7fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing validation data distribution to gain insights\n",
    "def plot_class_distribution(generator):\n",
    "    # Counting the number of samples for each class\n",
    "    class_counts = np.bincount(generator.classes)\n",
    "\n",
    "    # Getting the class names from the generator\n",
    "    class_names = list(generator.class_indices.keys())\n",
    "\n",
    "    # Creating a bar plot with class names on the x-axis and class counts on the y-axis\n",
    "    sns.barplot(x=class_names, y=class_counts)\n",
    "\n",
    "    # Rotating the x-axis labels for better readability if they are long\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Class Distribution for Validation Data\")\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution(validation_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a69557e-098b-48d6-a12b-2d12e96f2d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizing test data distribution to gain insights\n",
    "def plot_class_distribution(generator):\n",
    "    # Counting the number of samples for each class\n",
    "    class_counts = np.bincount(generator.classes)\n",
    "\n",
    "    # Getting the class names from the generator\n",
    "    class_names = list(generator.class_indices.keys())\n",
    "\n",
    "    # Creating a bar plot with class names on the x-axis and class counts on the y-axis\n",
    "    sns.barplot(x=class_names, y=class_counts)\n",
    "\n",
    "    # Rotating the x-axis labels for better readability if they are long\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.title(\"Class Distribution for Testing Data\")\n",
    "    plt.show()\n",
    "\n",
    "plot_class_distribution(test_gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed27ffbe-7a27-402c-9d2d-1dca184ca2ee",
   "metadata": {},
   "source": [
    "Dataset is imbalanced, hence, higher weights would be assigned to underrepresented class during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5031bc1a-45dd-4c6e-9119-951573042a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the InceptionV3 model\n",
    "base_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (299,299,3))\n",
    "#Adding new layers\n",
    "out = base_model.output\n",
    "pool = GlobalAveragePooling2D()(out)\n",
    "#Adding dropout layers to reduce overfitting\n",
    "pool = Dropout(0.5)(pool)\n",
    "output = Dense(1024, activation = 'relu')(pool)\n",
    "output = Dropout(0.5)(output)\n",
    "predictions = Dense(train_gen.num_classes, activation = 'softmax')(output)\n",
    "#Compiling layers to create new model\n",
    "model = Model(inputs = base_model.input, outputs = predictions)\n",
    "#Freezing the InceptionV3 model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41664468-2125-47e4-87c0-99b3826c16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Specifying the callback functions to be used in fine tuning model\n",
    "callbacks = [\n",
    "    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min'),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbef1c8-3b16-4ef1-9788-a402b2980e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adjusting weights based on differing class sizes\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_gen.classes),\n",
    "    y=train_gen.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41e0a6f-34bd-4035-93e2-ca85fa961bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine tuning the model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=train_gen.samples // train_gen.batch_size,\n",
    "    validation_data=validation_gen,\n",
    "    validation_steps=validation_gen.samples // validation_gen.batch_size,\n",
    "    epochs=10,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ead0a9-4b2b-4cfa-8a4c-b67e684b0d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Redefining the model creation function\n",
    "def create_model(learning_rate=0.001, dropout_rate=0.5, num_classes=None):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(299, 299, 3))\n",
    "    out = base_model.output\n",
    "    pool = GlobalAveragePooling2D()(out)\n",
    "    pool = Dropout(dropout_rate)(pool)\n",
    "    output = Dense(1024, activation='relu')(pool)\n",
    "    output = Dropout(dropout_rate)(output)\n",
    "    predictions = Dense(num_classes, activation='softmax')(output)\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc306a53-533a-4461-b86d-e4d1b6d535ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a custom KerasClassifier\n",
    "class KerasClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, build_fn=None, **sk_params):\n",
    "        self.build_fn = build_fn\n",
    "        self.sk_params = sk_params\n",
    "        self.model = None\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        self.model = self.build_fn(**self.filter_sk_params(self.build_fn))\n",
    "        return self.model.fit(X, y, **fit_params)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.model.predict(X), axis=1)\n",
    "\n",
    "    def filter_sk_params(self, fn):\n",
    "        res = {}\n",
    "        for k, v in self.sk_params.items():\n",
    "            if k in fn.__code__.co_varnames:\n",
    "                res[k] = v\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a055176-ebf3-4763-a996-9cd1bb0735e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a model with KerasClassifier wrapper for GridSearchCV\n",
    "num_classes = train_gen.num_classes\n",
    "model = KerasClassifier(build_fn=create_model, num_classes=num_classes, epochs=5, batch_size=16, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b68111-1d96-4607-8dc2-022113a83c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating custom scorer to work with modified GridSearchCV\n",
    "def evaluate_model(model, generator):\n",
    "    scores = model.evaluate(generator, steps=generator.samples // generator.batch_size)\n",
    "    return scores[1]  #Assuming accuracy is the main focus\n",
    "\n",
    "def custom_scorer(estimator, X):\n",
    "    return evaluate_model(estimator.model, X)\n",
    "\n",
    "custom_scorer = make_scorer(custom_scorer, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5182c72-5a63-45d6-8e4a-2a5cfc646dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'learning_rate': [1e-3, 1e-2],\n",
    "    'dropout_rate': [ 0.5, 0.7],\n",
    "    'batch_size': [16, 32]\n",
    "}\n",
    "\n",
    "#Performing GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=1, cv=3, scoring=custom_scorer)\n",
    "grid_result = grid.fit(train_gen, validation_data=validation_gen)\n",
    "\n",
    "#Summarizing the results of GridSearchCV\n",
    "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\n",
    "best_model = grid_result.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48b7c6e-76a4-4237-9c50-a794fa29dfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the model on the test set\n",
    "test_loss, test_acc = best_model.evaluate(test_gen)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2447242c-571f-4cb5-a422-f9a42697d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine-tuning the best model\n",
    "callbacksnew = [\n",
    "    ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min'),\n",
    "    EarlyStopping(monitor='val_loss', patience=5, mode='min', verbose=1)\n",
    "]\n",
    "\n",
    "class_weights_new = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_gen.classes),\n",
    "    y=train_gen.classes\n",
    ")\n",
    "class_weightsn = dict(enumerate(class_weights_new))\n",
    "\n",
    "historynew = best_model.fit(train_gen, validation_data=validation_gen, epochs=10, class_weight=class_weightsn, callbacks=callbacksnew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7937e2ce-2e59-417b-b187-9fc235d9e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating the model on the test set\n",
    "test_loss, test_acc = best_model.evaluate(test_gen)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d6db7e-4ae1-44b3-9eb9-866f597bf911",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generating confusion matrix\n",
    "def get_predictions_and_labels(generator, model):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Iterate over batches from the generator\n",
    "    for batch in generator:\n",
    "        imgs, labels = batch\n",
    "        preds = model.predict(imgs)\n",
    "        all_preds.extend(np.argmax(preds, axis=1))\n",
    "        all_labels.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels)\n",
    "#Getting predictions and true labels from the test generator\n",
    "y_pred, y_true = get_predictions_and_labels(test_gen, best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e00e0c-f262-4490-a3f7-52a6fe0184e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computing the confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "\n",
    "#Plotting confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage: assuming you have a list of class names\n",
    "class_names = list(test_gen.class_indices.keys())\n",
    "plot_confusion_matrix(cm, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdcad08-6bdc-4880-8a60-740c6e721b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the trained model\n",
    "model = tf.keras.models.load_model(\"C:\\\\Users\\\\user\\\\OneDrive - Ashesi University\\\\intro to ai\\\\venv\\\\best_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d757e51-8d42-4625-9ab3-8ae992e5363d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading additional information from Excel\n",
    "info_df = pd.read_excel(\"C:/Users/user/OneDrive - Ashesi University/intro to ai/Nigerianfood_additionalinfo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb405b-5649-4333-aefe-50fcbce62885",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the image for prediction\n",
    "def preprocess_image(img):\n",
    "    img = img.resize((299, 299))  # Resize image to the model's expected input size\n",
    "    img_array = np.array(img, dtype=np.float32)  # Convert image to numpy array with float32 type\n",
    "    if img_array.ndim == 2:  # Check if image is grayscale\n",
    "        img_array = np.stack([img_array] * 3, axis=-1)  # Convert grayscale to RGB\n",
    "    img_array /= 255.0  # Normalize to [0, 1]\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c25588-7b9b-4cf0-b942-3714bd79944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the food name based on predicted class index\n",
    "def get_food_name(predicted_class):\n",
    "    food_names = [\n",
    "        'Abacha and Ugba', 'Akara and Eko', 'Amala and Gbegiri-Ewedu', 'Asaro', 'Boli(Bole)', \n",
    "        'Chin Chin', 'Egusi Soup', 'Ewa-Agoyin', 'Fried plantains(Dodo)', 'Jollof Rice', \n",
    "        'Meat Pie', 'Moin-moin', 'Nkwobi', 'Okro Soup', 'Pepper Soup', 'Puff Puff', \n",
    "        'Suya', 'Vegetable Soup'\n",
    "    ]\n",
    "    return food_names[predicted_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb4e5bf4-7a7e-42a9-86f4-12b565e22c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting additional info based on the food name\n",
    "def get_additional_info(food_name):\n",
    "    if food_name in info_df['food_name'].values:\n",
    "        info = info_df[info_df['food_name'] == food_name].iloc[0]\n",
    "        return {\n",
    "            'Origin or State': info['Origin_or_State'],\n",
    "            'Popular Countries': info['Pop_Countries'],\n",
    "            'Health Benefits': info['Health_Benefits'],\n",
    "            'Calories': info['calories'],\n",
    "            'Nutrient Ratio': info['Nutrient_Ratio'],\n",
    "            'Ingredients': info['Ingredients'],\n",
    "            'Protein Content': info['Protein_Content'],\n",
    "            'Fat Content': info['Fat_Content'],\n",
    "            'Carbohydrate Content': info['Carbohydrate_Content'],\n",
    "            'Allergens': info['Allergens'],\n",
    "            'Mineral Content': info['Mineral-Content'],\n",
    "            'Vitamin Content': info['Vitamin_Content'],\n",
    "            'Suitability': info['Suitability'],\n",
    "            'Fiber Content': info['Fiber_Content']\n",
    "        }\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca51bf88-4a9a-451b-8115-32269ba3e617",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict and retrieve additional information\n",
    "def predict_and_get_info(image):\n",
    "    processed_image = preprocess_image(image)\n",
    "    predictions = model.predict(processed_image)\n",
    "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
    "    food_name = get_food_name(predicted_class)\n",
    "    additional_info = get_additional_info(food_name)\n",
    "\n",
    "    return food_name, additional_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd126ca7-8f76-4f71-89ff-4458041e97cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image to be predicted\n",
    "image_path = \"C:\\\\Users\\\\user\\\\OneDrive - Ashesi University\\\\intro to ai\\\\Nigeria\\\\Nkwobi\\\\20180617_095955.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbca10a-3c21-46a5-9a54-843cf83c83c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the image\n",
    "image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010788d8-cf8f-4ab9-af8e-e57122c2dc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting and getting additional information\n",
    "food_name, additional_info = predict_and_get_info(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08017a-0022-464b-9826-d2f8e666f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying results\n",
    "print(f\"Predicted Food: {food_name}\")\n",
    "if additional_info:\n",
    "    for key, value in additional_info.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "else:\n",
    "    print(\"No additional information available.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
